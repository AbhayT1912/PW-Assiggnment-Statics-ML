{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Regression Assignment\n"
      ],
      "metadata": {
        "id": "S-5EsWQsuR7x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. What is Simple Linear Regression?\n",
        "\n",
        "Ans:-It is one of the supervised machine learning algorithm/model, It's a statistical method used to find the best straight line that describes the relationship between two variables, like height and weight."
      ],
      "metadata": {
        "id": "TydpKPBCu74y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. What are the key assumptions of Simple Linear Regression?\n",
        "\n",
        "Ans:- The main assumptions are that the relationship is linear (a straight line), the data points are independent, the errors are normally distributed, and the spread of the errors is consistent (homoscedasticity)."
      ],
      "metadata": {
        "id": "IN56XFGJvPcT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. What does the coefficient m represent in the equation Y=mx+c?\n",
        "\n",
        "Ans:- m is the slope. It tells you how much Y is expected to increase or decrease when x increases by one unit."
      ],
      "metadata": {
        "id": "-m1DidpsvW55"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. What does the intercept c represent in the equation Y=mx+c?\n",
        "\n",
        "Ans:- c is the y-intercept. It's the predicted value of Y when x is equal to zero."
      ],
      "metadata": {
        "id": "K91lihsPve91"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. How do we calculate the slope m in Simple Linear Regression?\n",
        "\n",
        "Ans:- It's calculated with a formula that essentially measures how x and y move together (covariance) divided by how much x varies on its own (variance)."
      ],
      "metadata": {
        "id": "r7-JCIl2vmy3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. What is the purpose of the least squares method?\n",
        "\n",
        "Ans:- Its purpose is to find the best-fitting line by minimizing the total squared distance from each data point to the line."
      ],
      "metadata": {
        "id": "fKinknmXvtbq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. How is the coefficient of determination (R²) interpreted?\n",
        "\n",
        "Ans:- R-squared (R²) tells you the percentage of the variation in the outcome variable (Y) that can be explained by the predictor variable (x). An R² of 0.70 means 70% of Y's variation is explained by x."
      ],
      "metadata": {
        "id": "-53utSWhwp9U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. What is Multiple Linear Regression?\n",
        "\n",
        "Ans:- It's like simple linear regression, but it uses two or more predictor variables (x₁, x₂, ...) to predict a single outcome variable (Y)."
      ],
      "metadata": {
        "id": "JkTwxtR5wxqc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. What is the main difference between Simple and Multiple Linear Regression?\n",
        "\n",
        "Ans:- The number of predictor variables: simple has one, while multiple has more than one."
      ],
      "metadata": {
        "id": "HMriOSfKw5Ff"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. What are the key assumptions of Multiple Linear Regression?\n",
        "\n",
        "Ans:- It has the same assumptions as simple linear regression, plus an additional one: no multicollinearity, which means the predictor variables should not be highly correlated with each other."
      ],
      "metadata": {
        "id": "G60diY3LxAoV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. What is heteroscedasticity, and how does it affect the results?\n",
        "\n",
        "Ans:- Heteroscedasticity is when the spread of the model's errors is uneven. Imagine a funnel shape in the error plot. It makes your predictions less reliable."
      ],
      "metadata": {
        "id": "wbTnFmM2xHWt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. How can you improve a model with high multicollinearity?\n",
        "\n",
        "Ans:- You can either remove one of the highly correlated variables or combine them into a single, new variable."
      ],
      "metadata": {
        "id": "e8th4nK9xOps"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. How are categorical variables (like \"cat,\" \"dog,\" \"bird\") transformed for regression?\n",
        "\n",
        "Ans:- A common method is one-hot encoding, which creates a new binary (0 or 1) column for each category."
      ],
      "metadata": {
        "id": "U4A9MxF7xWEt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. What is the role of interaction terms?\n",
        "\n",
        "Ans:- An interaction term checks if the effect of one variable depends on the level of another variable. For example, a drug's effect might be different for men than for women."
      ],
      "metadata": {
        "id": "PPkSaLuBxdGU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "15. How does the interpretation of the intercept differ between Simple and Multiple Regression?\n",
        "\n",
        "Ans:- In simple regression, it's the value of Y when your single x is 0. In multiple regression, it's the value of Y when all predictor variables are 0."
      ],
      "metadata": {
        "id": "NpQ9DwaDxkAc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "16. What is the significance of the slope?\n",
        "\n",
        "Ans:- The slope indicates the strength and direction of a variable's relationship with the outcome. A larger slope means a stronger impact.\n",
        "\n"
      ],
      "metadata": {
        "id": "YftmZ_cQxsav"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "17. How does the intercept provide context?\n",
        "\n",
        "Ans:- The intercept acts as a baseline or starting point for the model's prediction before you consider the effect of any of the predictor variables."
      ],
      "metadata": {
        "id": "iqHHAGq1x1SJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "18. What are the limitations of using R² alone?\n",
        "\n",
        "Ans:- R² almost always increases when you add more variables, even if they're useless. This can be misleading and encourage overly complex models."
      ],
      "metadata": {
        "id": "MKJmzEddx8zH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "19. How would you interpret a large standard error for a coefficient?\n",
        "\n",
        "Ans:- A large standard error means there is a lot of uncertainty about that coefficient's true value. The variable might not be a reliable predictor."
      ],
      "metadata": {
        "id": "1H3MfJQcyCeC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "20. How is heteroscedasticity identified in residual plots?\n",
        "\n",
        "Ans:- It typically appears as a cone or fan shape, where the points spread out as the predicted values increase. It's important to fix because it violates a key assumption of the model.\n",
        "\n"
      ],
      "metadata": {
        "id": "nxlLFhgKyIid"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "21. What does a high R² but low adjusted R² mean?\n",
        "\n",
        "Ans:- This suggests you have added predictor variables that are not useful and are unnecessarily complicating the model. (Note: Adjusted R² is almost always lower than R², but a large drop is the key)."
      ],
      "metadata": {
        "id": "PruJ6H5yyQfW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "22. Why is it important to scale variables?\n",
        "\n",
        "Ans:- Scaling (or standardizing) variables puts them on a common scale, which allows you to fairly compare the size of their coefficients to see which one has a stronger effect."
      ],
      "metadata": {
        "id": "MDAIzPrXyXJd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "23. What is polynomial regression?\n",
        "\n",
        "Ans:- It's a type of regression that models a curved relationship between variables by including polynomial terms (e.g., x^2, x^3)."
      ],
      "metadata": {
        "id": "Il24pE5SydhG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "24. How does polynomial regression differ from linear regression?\n",
        "\n",
        "Ans:- Linear regression fits a straight line, while polynomial regression fits a curved line."
      ],
      "metadata": {
        "id": "Yj8r_FjeytT2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "25. When is polynomial regression used?\n",
        "\n",
        "Ans:- It's used when a scatter plot of your data clearly shows a non-linear, curved pattern."
      ],
      "metadata": {
        "id": "U3Z1FNeny8I3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "26. What is the general equation for polynomial regression?\n",
        "\n",
        "Ans:- It's an extension of the linear equation: Y=c+m1 x+m2 x^2+...+mn x^n. The highest power n is the \"degree\" of the polynomial."
      ],
      "metadata": {
        "id": "wbUsYrTzzCag"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "27. Can polynomial regression be applied to multiple variables?\n",
        "\n",
        "Ans:- Yes, you can create polynomial terms for multiple variables to capture complex curved surfaces instead of just flat planes."
      ],
      "metadata": {
        "id": "eLAWEmPYzZTD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "28. What are the limitations of polynomial regression?\n",
        "\n",
        "Ans:- The biggest limitation is overfitting. Using too high of a degree can create a \"wiggly\" line that fits the noise in your data but makes poor predictions on new data."
      ],
      "metadata": {
        "id": "1XBy0GI6zh96"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "29. What methods are used to select the right degree of a polynomial?\n",
        "\n",
        "Ans:- You can use metrics like Adjusted R², visual inspection of the curve, or techniques like cross-validation to see which degree performs best on unseen data."
      ],
      "metadata": {
        "id": "FpovsN1SztMp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "30. Why is visualization important in polynomial regression?\n",
        "\n",
        "Ans:- It's the best way to see if your curve is a sensible fit for the data or if it's overfitting (too wiggly) or underfitting (not capturing the curve)."
      ],
      "metadata": {
        "id": "KYl7B_Vyz1IQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "31. How is polynomial regression implemented in Python?\n",
        "\n",
        "Ans:- Typically, you use a library like scikit-learn. First, you use its PolynomialFeatures to generate the squared/cubed terms, and then you fit a regular LinearRegression model on those new terms."
      ],
      "metadata": {
        "id": "0axg_dgS0Ie6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "YSKOIfq60ZiM"
      }
    }
  ]
}